{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"1rkXQjHhqMaO"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QEjy4aitOsNb"},"outputs":[],"source":["import shutil\n","shutil.copytree('/content/drive/MyDrive/Personal/Study/Phd/Python/Examples/4.C-LSTM/training_data/conv_lstm/', '/content/training_data/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jz551QC6OuTA"},"outputs":[],"source":["!pip install scikit-learn\n","!pip install joblib soundfile speechpy librosa matplotlib\n","!pip install joblib==1.2.0\n","!pip install np_utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EpAx41nbOyFg"},"outputs":[],"source":["#from include.functions import initialise, load_data\n","#from include.stats import plot_accuracy_loss\n","import tensorflow as tf\n","from tensorflow.keras.layers import Layer, Conv2D, Flatten, Dense\n","from tensorflow.keras import layers, models, optimizers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import mnist\n","#from keras.utils import np_utils\n","import joblib\n","import os\n","#from keras.utils import np_utils\n","import sys\n","from keras import Sequential\n","from keras.layers import Dense, Dropout, LSTM, Conv1D, Flatten, MaxPooling1D\n","import matplotlib.pyplot as plt\n","###################################################\n","def load_data(load_from_file,name):\n","    if load_from_file:\n","        current_dir = os.getcwd()\n","        subdir = '\\\\training_data\\\\'\n","        save_dir = '/content/training_data'\n","\n","        x_train = joblib.load(os.path.join(save_dir, 'x_train_'+name+'.joblib'))\n","        x_test = joblib.load(os.path.join(save_dir, 'x_test_'+name+'.joblib'))\n","        y_train = joblib.load(os.path.join(save_dir, 'y_train_'+name+'.joblib'))\n","        y_test = joblib.load(os.path.join(save_dir, 'y_test_'+name+'.joblib'))\n","        num_labels = joblib.load(os.path.join(save_dir, 'num_labels_'+name+'.joblib'))\n","        #data = joblib.load(os.path.join(save_dir, 'data_'+name+'.joblib'))\n","        #labels = joblib.load(os.path.join(save_dir, 'labels_'+name+'.joblib'))\n","    else:\n","        #x_train, x_test, y_train, y_test, num_labels = extract_data()\n","        current_dir = os.getcwd()\n","        subdir = '\\\\training_data\\\\'\n","        save_dir = current_dir + subdir\n","        joblib.dump(x_train, os.path.join(save_dir, 'x_train_'+name+'.joblib'))\n","        joblib.dump(x_test, os.path.join(save_dir, 'x_test_'+name+'.joblib'))\n","        joblib.dump(y_train, os.path.join(save_dir, 'y_train_'+name+'.joblib'))\n","        joblib.dump(y_test, os.path.join(save_dir, 'y_test_'+name+'.joblib'))\n","        joblib.dump(num_labels, os.path.join(save_dir, 'num_labels_'+name+'.joblib'))\n","        #joblib.dump(data, os.path.join(save_dir, 'data_'+name+'.joblib'))\n","        #joblib.dump(labels, os.path.join(save_dir, 'labels_'+name+'.joblib'))\n","    return x_train,x_test,y_train,y_test,num_labels#,data, labels\n","###################################################\n","\n","\n","\n","def conv_lstm_example():\n","    print(\"*************START*************\\n\")\n","    #loadfromfile=False\n","    loadfromfile=True\n","    x_train,x_test,y_train,y_test,num_labels =load_data(load_from_file=loadfromfile,name= 'conv_lstm')\n","\n","    print(\"Before Reshape\")\n","    print(\"x_train.shape :\" +  str(x_train.shape) +\"    y_train.shape:\"+ str(y_train.shape))\n","    print(\"x_test.shape :\" +  str(x_test.shape) +\"    y_test.shape:\"+ str(y_test.shape))\n","\n","    from keras import utils\n","    y_train = utils.to_categorical(y_train)\n","    y_test = utils.to_categorical(y_test)\n","    in_shape = x_train[0].shape\n","\n","    #x_train = x_train.reshape(x_train.shape[0], in_shape[1], in_shape[0], 1)\n","    #x_test = x_test.reshape(x_test.shape[0], in_shape[1], in_shape[0], 1)\n","\n","    print(\"After Reshape\")\n","    print(\"x_train.shape :\" +  str(x_train.shape) +\"    y_train.shape:\"+ str(y_train.shape))\n","    print(\"x_test.shape :\" +  str(x_test.shape) +\"    y_test.shape:\"+ str(y_test.shape))\n","\n","    num_timesteps, num_features = x_train.shape[1], x_train.shape[2]\n","    num_classes = y_train.shape[1]\n","\n","    print(\"num_timesteps, num_features, num_classes\")\n","    print(\"num_timesteps:\" +str(num_timesteps) )\n","    print(\"num_features:\" +str(num_features))\n","    print(\"num_classes:\" +str(num_classes))\n","\n","    #####################\n","\n","    model = Sequential()\n","    model.add(Conv1D(128, kernel_size=5, activation='relu', input_shape=(num_timesteps, num_features)))\n","    model.add(MaxPooling1D(pool_size=2))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(64, return_sequences=True))\n","    model.add(Flatten())\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(num_classes, activation='softmax'))\n","\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    #####################\n","     #####################\n","    loss_history = []\n","    accuracy_history = []\n","\n","    epochs = 100\n","\n","    for epoch in range(epochs):\n","        # Train the model for one epoch\n","        history = model.fit(x_train, y_train, epochs=1, validation_data=(x_test,y_test), verbose=0)\n","\n","        # Record loss and accuracy values for plotting\n","        loss_history.append(history.history['loss'][0])\n","        accuracy_history.append(history.history['accuracy'][0])\n","\n","        # Display the loss and accuracy for the current epoch\n","        print(f\"Epoch {epoch + 1}/{epochs} - Loss: {loss_history[-1]:.4f} - Accuracy: {accuracy_history[-1]:.4f}\")\n","\n","        # Plot loss and accuracy\n","        plt.figure(figsize=(12, 4))\n","        plt.subplot(1, 2, 1)\n","        plt.plot(loss_history)\n","        plt.title('Loss vs. Epoch')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Loss')\n","\n","        plt.subplot(1, 2, 2)\n","        plt.plot(accuracy_history)\n","        plt.title('Accuracy vs. Epoch')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Accuracy')\n","\n","        plt.tight_layout()\n","        plt.show()\n","    \"\"\"\n","    history = model.fit(x_train, y_train,  batch_size=32, epochs=50,shuffle=True,validation_data=(x_test,y_test))\n","\n","    loss, acc = model.evaluate(x_test, y_test)\n","    print(\"Accuracy: {:.2f}%\".format(acc*100))\n","    print(\"Loss: {:.2f}%\".format(loss*100))\n","    print(\"Highest Accuracy: {:.2f}%\".format(max(history.history['val_accuracy'])*100))\n","\n","    \"\"\"\n","    import tensorflow as tf\n","    model.save('/content/drive/MyDrive/Personal/Study/Phd/Python/Examples/4.C-LSTM/model/conv_lstm_classifier.tf')\n","    #tf.saved_model.save(model, \"model/conv_lstm_classifier\")\n","\n","    print('conv_lstm Done')\n","\n","\n","if __name__ == \"__main__\":\n","    conv_lstm_example()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1AGe1n-7cZDM0cQz2Uno8r3lN_B8UXRKv","authorship_tag":"ABX9TyMy0/WwxEWlLvYh5PCMnk/F"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}