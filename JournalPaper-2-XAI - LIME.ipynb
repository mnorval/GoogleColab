{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Fsue5qf8N3RUXnUAqdae32F6N9s2zjgp","authorship_tag":"ABX9TyMbd0utcvt3rGtXCziD5FpK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# @title Step 1 { vertical-output: true }\n","import shutil\n","shutil.copytree('/content/drive/MyDrive/Personal/Study/Phd/Python/Examples/4.C-LSTM/training_data/conv_lstm/', '/content/training_data_conv_lstm/', dirs_exist_ok=True)\n","shutil.copytree('/content/drive/MyDrive/Personal/Study/Phd/Python/Examples/4.C-LSTM/training_data/Dendritic_CapsNets/', '/content/training_data_Dendritic_CapsNets/', dirs_exist_ok=True)\n","shutil.copytree('/content/drive/MyDrive/Personal/Study/Phd/Python/Examples/4.C-LSTM/training_data/cnn/', '/content/training_data_cnn/', dirs_exist_ok=True)\n","# Install necessary libraries\n","!pip install scikit-learn\n","!pip install joblib soundfile speechpy librosa matplotlib\n","!pip install joblib==1.2.0\n","!pip install np_utils\n","!pip install lime\n","!pip install shap\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Layer, Conv2D, Flatten, Dense\n","from tensorflow.keras import layers, models, optimizers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import mnist\n","#from keras.utils import np_utils\n","import joblib\n","import os\n","\n","#clstm_model = tf.keras.models.load_model(\"/content/drive/MyDrive/Personal/Study/Phd/Python/Examples/4.C-LSTM/model/conv_lstm_classifier.tf\")\n","#clstm_model.summary()\n","#capsnet_model = tf.keras.models.load_model(\"/content/drive/MyDrive/Personal/Study/Phd/Python/Examples/4.C-LSTM/model/Dendritic_CapsNets.tf\")\n","#capsnet_model.summary()"],"metadata":{"id":"0EgpzCsV58jb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title CNN LIME - Random Data - Working\n","# Import necessary libraries\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","import lime\n","from lime import lime_image\n","from skimage.segmentation import mark_boundaries\n","import matplotlib.pyplot as plt\n","\n","# Create a simple CNN model\n","def create_cnn_model(input_shape=(64, 64, 3), num_classes=2):\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Conv2D(64, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(num_classes, activation='softmax'))\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Generate sample data\n","def generate_sample_data(num_samples=1000, img_size=(64, 64, 3), num_classes=2):\n","    X = np.random.rand(num_samples, *img_size)\n","    y = np.random.randint(num_classes, size=num_samples)\n","    return X, y\n","\n","# Split data into training and testing sets\n","X, y = generate_sample_data()\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# One-hot encode the labels\n","num_classes = len(np.unique(y))\n","y_train_one_hot = np.eye(num_classes)[y_train]\n","y_test_one_hot = np.eye(num_classes)[y_test]\n","\n","# Train the CNN model\n","input_shape = x_train.shape[1:]\n","cnn_test_model = create_cnn_model(input_shape, num_classes)\n","cnn_test_model.fit(x_train, y_train_one_hot, epochs=4, batch_size=32, validation_split=0.2)\n","cnn_test_model.summary()\n","# Now, let's use LIME for explainability on a single test instance\n","# Pick a random test instance\n","print(\"x_test - Shape\")\n","print(x_test.shape)\n","\n","test_instance = x_test[0]\n","\n","# Create a LIME explainer for image classification\n","explainer = lime_image.LimeImageExplainer()\n","\n","# Explain the model's prediction on the test instance\n","explanation = explainer.explain_instance(test_instance, cnn_test_model.predict, top_labels=1, hide_color=0, num_samples=1000)\n","\n","# Display the original image and the LIME explanation\n","plt.subplot(1, 2, 1)\n","plt.imshow(test_instance)\n","plt.title('Original Image')\n","\n","plt.subplot(1, 2, 2)\n","temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n","plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n","plt.title('LIME Explanation')\n","\n","plt.show()\n","\n","\n"],"metadata":{"id":"SGVttfJBICmv","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title CNN LIME - Random Audio Data - NOT Working\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from lime.lime_image import LimeImageExplainer\n","import shap\n","\n","# Generate synthetic data\n","num_samples = 200\n","num_features = 1047\n","data_shape = (num_samples, num_features, 40, 1)\n","data = np.random.normal(loc=0.0, scale=1.0, size=data_shape)\n","\n","# Generate random binary labels (0 or 1)\n","labels = np.random.randint(2, size=num_samples)\n","\n","# Split data into train and test sets\n","train_size = 0.8\n","train_data, test_data, train_labels, test_labels = train_test_split(\n","    data, labels, train_size=train_size, random_state=200\n",")\n","\n","# Create a simple CNN model\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(num_features, 40, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile and train the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(train_data, train_labels, epochs=2, batch_size=32)\n","\n","# LIME explanation\n","explainer = LimeImageExplainer()\n","explanation = explainer.explain_instance(test_data[0], model.predict)\n","explanation.show_in_notebook()\n","\n","# SHAP explanation\n","#explainer_shap = shap.Explainer(model, train_data)\n","#shap_values = explainer_shap(test_data)\n","#shap.summary_plot(shap_values, test_data)\n","\n","# Now you have both LIME and SHAP explanations!\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":479},"id":"TK3e578UAQ2W","executionInfo":{"status":"error","timestamp":1707488830067,"user_tz":-120,"elapsed":26423,"user":{"displayName":"Michael Norval","userId":"02369176901953918409"}},"outputId":"382e32e3-54a4-44d1-ea0b-6dbac665a294"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","5/5 [==============================] - 12s 2s/step - loss: 36.4196 - accuracy: 0.5625\n","Epoch 2/2\n","5/5 [==============================] - 7s 1s/step - loss: 30.9415 - accuracy: 0.4437\n"]},{"output_type":"error","ename":"ValueError","evalue":"the input array must have size 3 along `channel_axis`, got (1047, 40, 1)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-ebb1009f5de7>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# LIME explanation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLimeImageExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mexplanation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mexplanation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_in_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lime/lime_image.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mfudged_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lime/lime_image.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[1;32m    180\u001b[0m                                                     random_seed=random_seed)\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lime/wrappers/scikit_image.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/segmentation/_quickshift.py\u001b[0m in \u001b[0;36mquickshift\u001b[0;34m(image, ratio, kernel_size, max_dist, return_tree, sigma, convert2lab, random_seed, channel_axis)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only RGB images can be converted to Lab space.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/_shared/utils.py\u001b[0m in \u001b[0;36mfixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchannel_axis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;31m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mrgb2lab\u001b[0;34m(rgb, illuminant, observer, channel_axis)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mwiki\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mStandard_illuminant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \"\"\"\n\u001b[0;32m-> 1139\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxyz2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb2xyz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0milluminant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/_shared/utils.py\u001b[0m in \u001b[0;36mfixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchannel_axis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;31m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mrgb2xyz\u001b[0;34m(rgb, channel_axis)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;31m# Follow the algorithm from http://www.easyrgb.com/index.php\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;31m# except we don't multiply/divide by 100 in the conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_colorarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.04045\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.055\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1.055\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36m_prepare_colorarray\u001b[0;34m(arr, force_copy, channel_axis)\u001b[0m\n\u001b[1;32m    138\u001b[0m         msg = (f'the input array must have size 3 along `channel_axis`, '\n\u001b[1;32m    139\u001b[0m                f'got {arr.shape}')\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mfloat_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_supported_float_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: the input array must have size 3 along `channel_axis`, got (1047, 40, 1)"]}]},{"cell_type":"code","source":["# @title CNN LIME - Random Audio Data - Working\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from lime import lime_image\n","import matplotlib.pyplot as plt\n","\n","###################################################\n","def load_data(load_from_file,name):\n","    if load_from_file:\n","        current_dir = os.getcwd()\n","        subdir = '\\\\training_data\\\\'\n","        save_dir = '/content/training_data_cnn'\n","\n","        x_train = joblib.load(os.path.join(save_dir, 'x_train_'+name+'.joblib'))\n","        x_test = joblib.load(os.path.join(save_dir, 'x_test_'+name+'.joblib'))\n","        y_train = joblib.load(os.path.join(save_dir, 'y_train_'+name+'.joblib'))\n","        y_test = joblib.load(os.path.join(save_dir, 'y_test_'+name+'.joblib'))\n","        num_labels = joblib.load(os.path.join(save_dir, 'num_labels_'+name+'.joblib'))\n","        #data = joblib.load(os.path.join(save_dir, 'data_'+name+'.joblib'))\n","        #labels = joblib.load(os.path.join(save_dir, 'labels_'+name+'.joblib'))\n","    else:\n","        #x_train, x_test, y_train, y_test, num_labels = extract_data()\n","        current_dir = os.getcwd()\n","        subdir = '\\\\training_data\\\\'\n","        save_dir = current_dir + subdir\n","        joblib.dump(x_train, os.path.join(save_dir, 'x_train_'+name+'.joblib'))\n","        joblib.dump(x_test, os.path.join(save_dir, 'x_test_'+name+'.joblib'))\n","        joblib.dump(y_train, os.path.join(save_dir, 'y_train_'+name+'.joblib'))\n","        joblib.dump(y_test, os.path.join(save_dir, 'y_test_'+name+'.joblib'))\n","        joblib.dump(num_labels, os.path.join(save_dir, 'num_labels_'+name+'.joblib'))\n","        #joblib.dump(data, os.path.join(save_dir, 'data_'+name+'.joblib'))\n","        #joblib.dump(labels, os.path.join(save_dir, 'labels_'+name+'.joblib'))\n","    return x_train,x_test,y_train,y_test,num_labels#,data, labels\n","###################################################\n","\n","loadfromfile=True\n","x_train,x_test,y_train,y_test,num_labels =load_data(load_from_file=loadfromfile,name= 'cnn')\n","\n","from keras import utils\n","y_train = utils.to_categorical(y_train)\n","y_test = utils.to_categorical(y_test)\n","in_shape = x_train[0].shape\n","\n","x_train = x_train.reshape(x_train.shape[0], in_shape[1], in_shape[0], 1)\n","x_test = x_test.reshape(x_test.shape[0], in_shape[1], in_shape[0], 1)\n","\n","\n","num_timesteps, num_features = x_train.shape[1], x_train.shape[2]\n","#num_classes = y_train.shape[1]\n","num_classes=8\n","###################################################\n","\n","# Assuming x_test has shape (200, 1047, 40, 1)\n","num_samples, duration, n_mels, channels = x_test.shape\n","\n","# Reshape data for the LimeImageExplainer\n","x_test_reshaped = x_test.reshape((-1, n_mels, duration, channels))\n","\n","# Create a simple CNN model for audio classification\n","def create_audio_cnn_model(input_shape):\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Conv2D(64, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(num_classes, activation='softmax'))\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Create a LIME explainer for image classification\n","explainer = lime_image.LimeImageExplainer()\n","\n","# Explain the model's predictions on multiple test instances\n","for i in range(num_samples):\n","    test_instance = x_test_reshaped[i]\n","\n","    # Train the CNN model\n","    audio_cnn_model = create_audio_cnn_model(test_instance.shape)\n","    audio_cnn_model.fit(x_train, y_train_one_hot, epochs=5, batch_size=32, validation_split=0.2)\n","\n","    # Explain the model's prediction on the test instance\n","    explanation = explainer.explain_instance(test_instance, audio_cnn_model.predict, top_labels=1, hide_color=0, num_samples=1000)\n","\n","    # Display the original spectrogram and the LIME explanation\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(test_instance[:, :, 0], cmap='viridis', origin='lower')\n","    plt.title('Original Spectrogram')\n","\n","    plt.subplot(1, 2, 2)\n","    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n","    plt.imshow(temp, cmap='viridis', origin='lower')\n","    plt.title('LIME Explanation')\n","\n","    plt.show()\n","\n","\n"],"metadata":{"cellView":"form","id":"fnDd3CcpzUxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title DendCaps LIME\n","#from include.functions import initialise, load_data\n","#from include.stats import plot_accuracy_loss\n","import numpy as np\n","import sys\n","import lime\n","from lime import lime_image\n","from skimage.segmentation import mark_boundaries\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Layer, Conv2D, Flatten, Dense\n","from tensorflow.keras import layers, models, optimizers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import mnist\n","import sys\n","from keras import Sequential\n","from keras.layers import LSTM,Dense, Dropout, Conv2D, Flatten,BatchNormalization, Activation, MaxPooling2D,Reshape\n","import joblib\n","import os\n","###################################################\n","def load_data(load_from_file,name):\n","    if load_from_file:\n","        current_dir = os.getcwd()\n","        subdir = '\\\\training_data\\\\'\n","        save_dir = '/content/training_data_Dendritic_CapsNets'\n","\n","        x_train = joblib.load(os.path.join(save_dir, 'x_train_'+name+'.joblib'))\n","        x_test = joblib.load(os.path.join(save_dir, 'x_test_'+name+'.joblib'))\n","        y_train = joblib.load(os.path.join(save_dir, 'y_train_'+name+'.joblib'))\n","        y_test = joblib.load(os.path.join(save_dir, 'y_test_'+name+'.joblib'))\n","        num_labels = joblib.load(os.path.join(save_dir, 'num_labels_'+name+'.joblib'))\n","        #data = joblib.load(os.path.join(save_dir, 'data_'+name+'.joblib'))\n","        #labels = joblib.load(os.path.join(save_dir, 'labels_'+name+'.joblib'))\n","    else:\n","        #x_train, x_test, y_train, y_test, num_labels = extract_data()\n","        current_dir = os.getcwd()\n","        subdir = '\\\\training_data\\\\'\n","        save_dir = current_dir + subdir\n","        joblib.dump(x_train, os.path.join(save_dir, 'x_train_'+name+'.joblib'))\n","        joblib.dump(x_test, os.path.join(save_dir, 'x_test_'+name+'.joblib'))\n","        joblib.dump(y_train, os.path.join(save_dir, 'y_train_'+name+'.joblib'))\n","        joblib.dump(y_test, os.path.join(save_dir, 'y_test_'+name+'.joblib'))\n","        joblib.dump(num_labels, os.path.join(save_dir, 'num_labels_'+name+'.joblib'))\n","        #joblib.dump(data, os.path.join(save_dir, 'data_'+name+'.joblib'))\n","        #joblib.dump(labels, os.path.join(save_dir, 'labels_'+name+'.joblib'))\n","    return x_train,x_test,y_train,y_test,num_labels#,data, labels\n","###################################################\n","###################################################\n","# Squash function\n","def squash(x, axis=-1):\n","    s_squared_norm = tf.reduce_sum(tf.square(x), axis=axis, keepdims=True)\n","    scale = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + 1e-7)\n","    return scale * x\n","\n","###################################################\n","# Define Capsule Layer\n","class CapsuleLayer(layers.Layer):\n","    def __init__(self, num_capsules, dim_capsule, routings=3, **kwargs):\n","        super(CapsuleLayer, self).__init__(**kwargs)\n","        self.num_capsules = num_capsules\n","        self.dim_capsule = dim_capsule\n","        self.routings = routings\n","\n","    def build(self, input_shape):\n","        self.kernel = self.add_weight(name='capsule_kernel',\n","                                      shape=(input_shape[-1], self.num_capsules * self.dim_capsule),\n","                                      initializer='glorot_uniform',\n","                                      trainable=True)\n","\n","    def call(self, inputs):\n","        # Following is a simplified routing algorithm\n","        inputs = tf.keras.backend.reshape(inputs, (-1, inputs.shape[-1]))\n","        u = tf.keras.backend.dot(inputs, self.kernel)\n","        u = tf.keras.backend.reshape(u, (-1, self.num_capsules, self.dim_capsule))\n","        b = tf.zeros_like(u[:, :, 0])\n","        for i in range(self.routings):\n","            c = tf.nn.softmax(b, axis=1)\n","            s = tf.reduce_sum(c[:, :, tf.newaxis] * u, axis=1)\n","            v = squash(s)\n","            b = b + tf.reduce_sum(u * v[:, tf.newaxis, :], axis=2)\n","        return v\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            'num_capsules': self.num_capsules,\n","            'dim_capsule': self.dim_capsule,\n","            'routings': self.routings\n","        })\n","        return config\n","###################################################\n","# Custom Dendritic Layer\n","class DendriticLayer(layers.Layer):\n","    def __init__(self, units, segments):\n","        super(DendriticLayer, self).__init__()\n","        self.units = units\n","        self.segments = segments\n","\n","    def build(self, input_shape):\n","        self.segment_weights = []\n","        self.segment_biases = []\n","        for _ in range(self.segments):\n","            self.segment_weights.append(self.add_weight(\n","                name='dend1',\n","                shape=(input_shape[-1], self.units),\n","                initializer='random_normal',\n","                trainable=True))\n","            self.segment_biases.append(self.add_weight(\n","                name='dend2',\n","                shape=(self.units,),\n","                initializer='zeros',\n","                trainable=True))\n","\n","        self.soma_weight = self.add_weight(\n","            name='dend3',\n","            shape=(self.units * self.segments, self.units),\n","            initializer='random_normal',\n","            trainable=True)\n","        self.soma_bias = self.add_weight(\n","            name='dend4',\n","            shape=(self.units,),\n","            initializer='zeros',\n","            trainable=True)\n","\n","    def call(self, inputs):\n","        outputs = []\n","        for i in range(self.segments):\n","            x = tf.matmul(inputs, self.segment_weights[i]) + self.segment_biases[i]\n","            x = tf.nn.relu(x)\n","            outputs.append(x)\n","\n","        concat = tf.concat(outputs, axis=-1)\n","        soma_output = tf.matmul(concat, self.soma_weight) + self.soma_bias\n","        soma_output = tf.nn.relu(soma_output)\n","        return soma_output\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            'units': self.units,\n","            'segments': self.segments\n","        })\n","        return config\n","###################################################\n","def DendCaps():\n","\n","    loadfromfile=True\n","    x_train,x_test,y_train,y_test,num_labels =load_data(load_from_file=loadfromfile,name= 'Dendritic_CapsNets')\n","\n","    from keras import utils\n","    y_train = utils.to_categorical(y_train)\n","    y_test = utils.to_categorical(y_test)\n","    in_shape = x_train[0].shape\n","\n","    x_train = x_train.reshape(x_train.shape[0], in_shape[1], in_shape[0], 1)\n","    x_test = x_test.reshape(x_test.shape[0], in_shape[1], in_shape[0], 1)\n","\n","    num_timesteps, num_features = x_train.shape[1], x_train.shape[2]\n","    num_classes = 8   #y1_train.shape[1]\n","    ###################################################\n","    ###################################################\n","    # Define CNN with Dendritic Layer Followed by Capsule Layer\n","    import matplotlib.pyplot as plt\n","\n","    input_shape = (num_timesteps, num_features, 1)\n","    inputs = tf.keras.Input(shape=input_shape)\n","    conv1 = layers.Conv2D(128, (3, 3), activation='relu')(inputs)\n","    conv2 = layers.Conv2D(32, (3, 3), activation='relu')(conv1)\n","    pooling1 = layers.MaxPooling2D(pool_size=2)(conv2)\n","    dropout1 = layers.Dropout(0.5)(pooling1)\n","    flatten1 = layers.Flatten()(dropout1)\n","    dendritic = DendriticLayer(64, 2)(flatten1)  # 64 units, 2 segments\n","    capsule = CapsuleLayer(num_capsules=10, dim_capsule=32, routings=3)(dendritic)\n","    #flatten2 = layers.Flatten()(capsule)\n","    dense1 = Dense(32, activation='relu')(capsule)\n","    dropout2 = layers.Dropout(0.5)(dense1)\n","    outputs = Dense(num_classes, activation='softmax')(dropout2)\n","    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","\n","    # Compile and Train\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","  #####################\n","    loss_history = []\n","    accuracy_history = []\n","\n","    epochs = 100\n","\n","    for epoch in range(epochs):\n","        # Train the model for one epoch\n","        history = model.fit(x_train, y_train, epochs=1, validation_data=(x_test,y_test), verbose=0)\n","\n","        # Record loss and accuracy values for plotting\n","        loss_history.append(history.history['loss'][0])\n","        accuracy_history.append(history.history['accuracy'][0])\n","\n","        # Display the loss and accuracy for the current epoch\n","        print(f\"Epoch {epoch + 1}/{epochs} - Loss: {loss_history[-1]:.4f} - Accuracy: {accuracy_history[-1]:.4f}\")\n","\n","        # Plot loss and accuracy\n","        \"\"\"\n","        plt.figure(figsize=(12, 4))\n","        plt.subplot(1, 2, 1)\n","        plt.plot(loss_history)\n","        plt.title('Loss vs. Epoch')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Loss')\n","\n","        plt.subplot(1, 2, 2)\n","        plt.plot(accuracy_history)\n","        plt.title('Accuracy vs. Epoch')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Accuracy')\n","\n","        plt.tight_layout()\n","        plt.show()\n","        \"\"\"\n","\n","  #####################\n","    history = model.fit(x_train, y_train, batch_size=32, epochs=5,shuffle=True,validation_split=0.05)\n","\n","    # Pick a random test instance\n","    test_instance = x_test[0]\n","\n","    # Create a LIME explainer for image classification\n","    explainer = lime_image.LimeImageExplainer()\n","\n","    # Explain the model's prediction on the test instance\n","    explanation = explainer.explain_instance(test_instance, cnn_model.predict, top_labels=1, hide_color=0, num_samples=1000)\n","\n","    # Display the original image and the LIME explanation\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(test_instance)\n","    plt.title('Original Image')\n","\n","    plt.subplot(1, 2, 2)\n","    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n","    plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n","    plt.title('LIME Explanation')\n","\n","    plt.show()\n","\n","    print(\"DendCaps Done\")\n","\n","if __name__ == \"__main__\":\n","    #initialise()\n","    DendCaps()"],"metadata":{"cellView":"form","id":"znV5gj_43ni2"},"execution_count":null,"outputs":[]}]}